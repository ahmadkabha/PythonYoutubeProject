{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-chorus",
   "metadata": {
    "id": "given-chorus"
   },
   "source": [
    "# Welcome to Amazon Reviews Sentiment Analysis project\n",
    "In this project we will be taking in reviews from random products on amazon and analyzing the sentiment of the review according to the word choice of the reivewer.\n",
    "Reviews are considered positive if theyre given 4 or more stars (out of 5).\n",
    "Reviews are considered negative if theyre given 2 or less stars (out of 5).\n",
    "Reviews are considered neutral if theyre given 3 stars, so we will be disregarding all 3star reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-jones",
   "metadata": {},
   "source": [
    "By: Awsam Agbarya and Ahmad Kabha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-apache",
   "metadata": {
    "id": "previous-apache"
   },
   "source": [
    "______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-complex",
   "metadata": {
    "id": "detailed-complex"
   },
   "source": [
    "To implement this project we are going to be using different NLP oriented libraries along with sklearn and tenserflow for trying our different models and picking the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "single-cabin",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "single-cabin",
    "outputId": "bd63c31a-bc7f-4135-f8e0-42003c741df1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from langdetect import detect\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-perspective",
   "metadata": {
    "id": "senior-perspective"
   },
   "source": [
    "We import out dataset that has all the reviews including a title and a score(amount of stars out of 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-extent",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "alien-extent",
    "outputId": "3278cef5-03e1-452b-edc3-f4e4e6f5a31e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>I hope a lot of people hear this cd. We need m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST</td>\n",
       "      <td>The music of Yasunori Misuda is without questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true</td>\n",
       "      <td>Probably the greatest soundtrack in history! U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>There's a reason for the price</td>\n",
       "      <td>There's a reason this CD is so expensive, even...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                  title  \\\n",
       "0      5                              Inspiring   \n",
       "1      5  The best soundtrack ever to anything.   \n",
       "2      4                       Chrono Cross OST   \n",
       "3      5                    Too good to be true   \n",
       "4      5         There's a reason for the price   \n",
       "\n",
       "                                              review  \n",
       "0  I hope a lot of people hear this cd. We need m...  \n",
       "1  I'm reading a lot of reviews saying that this ...  \n",
       "2  The music of Yasunori Misuda is without questi...  \n",
       "3  Probably the greatest soundtrack in history! U...  \n",
       "4  There's a reason this CD is so expensive, even...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "labels =['score', 'title','review']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-friday",
   "metadata": {
    "id": "excited-friday"
   },
   "source": [
    "# Matching the dataset to our project\n",
    "We need to switch the format of the dataset to something easier to deal with, and more applicable for a classification problem,\n",
    "Therefore we have to combine the title within the start of the review as one feature, and we switch the values of the score from 0-1 instead of 1-5 (the same way it was explained earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "golden-mediterranean",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "golden-mediterranean",
    "outputId": "5174fed8-d1ca-4237-c099-de43f04aba1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inspiring I hope a lot of people hear this cd....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Too good to be true Probably the greatest soun...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There's a reason for the price There's a reaso...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39993</th>\n",
       "      <td>A mom of three We bought this tent for my daug...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>we don't wish to be disturbed I bought this to...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>Pacific play tent - Lots of fun &amp; adventure pl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>A nice hideaway... Our one year old really enj...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>Just a manual Book is too basic. Majority cove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31820 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  score\n",
       "0      Inspiring I hope a lot of people hear this cd....    1.0\n",
       "1      The best soundtrack ever to anything. I'm read...    1.0\n",
       "2      Chrono Cross OST The music of Yasunori Misuda ...    1.0\n",
       "3      Too good to be true Probably the greatest soun...    1.0\n",
       "4      There's a reason for the price There's a reaso...    1.0\n",
       "...                                                  ...    ...\n",
       "39993  A mom of three We bought this tent for my daug...    1.0\n",
       "39994  we don't wish to be disturbed I bought this to...    1.0\n",
       "39995  Pacific play tent - Lots of fun & adventure pl...    1.0\n",
       "39996  A nice hideaway... Our one year old really enj...    1.0\n",
       "39997  Just a manual Book is too basic. Majority cove...    0.0\n",
       "\n",
       "[31820 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCombined=pd.DataFrame(index=(range(39998)), columns=['review','score'])\n",
    "dfCombined['review']=df['title']+' '+df['review']\n",
    "dfCombined['score'] = df['score']\n",
    "dfCombined.loc[dfCombined.score==2, 'score'] =0\n",
    "dfCombined.loc[dfCombined.score==1, 'score'] =0\n",
    "dfCombined.loc[dfCombined.score==5, 'score'] =1\n",
    "dfCombined.loc[dfCombined.score==4, 'score'] =1\n",
    "dfCombined.loc[dfCombined.score==3, 'score'] =np.NaN\n",
    "dfCombined=dfCombined.dropna() \n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-cannon",
   "metadata": {
    "id": "agricultural-cannon"
   },
   "source": [
    "Our reviews include entries in other languages like spanish.\n",
    "While we want to make our model as inclusive as possible, we have a very small amount of spanish reviews compared to english, therefore the model will not have enough data to be trained to recognize sentiment in spanish.\n",
    "We get rid of all spanish reviews for better results for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "needed-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "needed-niagara",
    "outputId": "37bd5860-a8fe-44b0-c5c6-409e8ef37cb9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of spanish entries removed: 65\n"
     ]
    }
   ],
   "source": [
    "dfEnglish =dfCombined\n",
    "counter=0\n",
    "for key,value in dfEnglish['review'].iteritems():\n",
    "    if(key==22000):\n",
    "        continue\n",
    "    lang = detect(value)\n",
    "    if(lang!='en'):\n",
    "        counter+=1\n",
    "        dfEnglish=dfEnglish.drop(key)\n",
    "dfEnglish = dfEnglish.dropna() \n",
    "print('Amount of spanish entries removed:',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-director",
   "metadata": {
    "id": "positive-director"
   },
   "source": [
    "We started the dataset with 39997 entries, but we cleaned the model from some unecessary entries, therefore we reset the index\n",
    "\n",
    "We also do a quick check on the balance of the data after we got rid of the unecessary entries. imbalanced data could cause problems that we need to deal with, therefore its good to check the balance before we begin processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceramic-irish",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "ceramic-irish",
    "outputId": "becc89e3-f322-4d13-c634-18ea42a2f07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% 50.74161549362305\n",
      "balanced data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inspiring I hope a lot of people hear this cd....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Too good to be true Probably the greatest soun...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There's a reason for the price There's a reaso...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31750</th>\n",
       "      <td>A mom of three We bought this tent for my daug...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31751</th>\n",
       "      <td>we don't wish to be disturbed I bought this to...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31752</th>\n",
       "      <td>Pacific play tent - Lots of fun &amp; adventure pl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31753</th>\n",
       "      <td>A nice hideaway... Our one year old really enj...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31754</th>\n",
       "      <td>Just a manual Book is too basic. Majority cove...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31755 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  score\n",
       "0      Inspiring I hope a lot of people hear this cd....    1.0\n",
       "1      The best soundtrack ever to anything. I'm read...    1.0\n",
       "2      Chrono Cross OST The music of Yasunori Misuda ...    1.0\n",
       "3      Too good to be true Probably the greatest soun...    1.0\n",
       "4      There's a reason for the price There's a reaso...    1.0\n",
       "...                                                  ...    ...\n",
       "31750  A mom of three We bought this tent for my daug...    1.0\n",
       "31751  we don't wish to be disturbed I bought this to...    1.0\n",
       "31752  Pacific play tent - Lots of fun & adventure pl...    1.0\n",
       "31753  A nice hideaway... Our one year old really enj...    1.0\n",
       "31754  Just a manual Book is too basic. Majority cove...    0.0\n",
       "\n",
       "[31755 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEnglish= dfEnglish.reset_index(drop=True)\n",
    "\n",
    "\n",
    "bad=dfEnglish.loc[dfEnglish['score']==0]['review'].count()\n",
    "good=dfEnglish.loc[dfEnglish['score']==1]['review'].count()\n",
    "precentage = 100*good/(bad+good)\n",
    "print('%',precentage)\n",
    "if(precentage>99 or precentage<1): print(\"Extremely imbalanced data\")\n",
    "elif(precentage>80 or precentage<20): print(\"Moderately imbalanced data\")\n",
    "elif(precentage>60 or precentage<40): print(\"Mildly imbalanced data\")\n",
    "else: print(\"balanced data\")\n",
    "dfEnglish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-personal",
   "metadata": {
    "id": "smart-personal"
   },
   "source": [
    "# PreProcessing of our data\n",
    "To make things easier to learn for our model we have to eleminate as many unecessary features in the reviews that have no contribution to sentiment:\n",
    "1. We turn all the letters to lower case to remove the differentiation between the same word with a capital letter and without\n",
    "2. Reviews sometimes has reference links to websites and other things, the links themselves do not have a meaning therefore we remove them\n",
    "3. While punctuation is important for meaning, it is rarely a major contributer to the sentiment therefore we get rid of it.\n",
    "4. We split the sentences into words through a tokenizer to process each word individually\n",
    "5. We remove all none english alphabetical letters from the sentences (things like numbers)\n",
    "6. We remove all english stopwords, stopwords are common english words and connectors for context and grammatical use that do not contribute to sentiment and theyre too frequent in english to make any relevance being used in a negative or positive manner (examples of stop words will be printed below)\n",
    "7. We stem all the words into it's root to remove the differentiation between words that have the same meaning but with different suffix/prefixes (example, close and closely, go and going, etc) this is done to limit the amount of words in our vocabulary that have similar sentiment yet not the same word\n",
    "8. We join back all the words of each review into one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aboriginal-color",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aboriginal-color",
    "outputId": "12c19944-e62f-4afa-db5c-fa832e53fbc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['inspir hope lot peopl hear cd need strong posit vibe like great vocal fresh tune crosscultur happi blue gut pop sound catchi matur',\n",
       " 'best soundtrack ever anyth read lot review say best soundtrack figur write review disagre bit opinino yasunori mitsuda ultim masterpiec music timeless listen year beauti simpli refus fadeth price tag pretti stagger must say go buy cd much money one feel would worth everi penni',\n",
       " 'chrono cross ost music yasunori misuda without question close second great nobuo uematsuchrono cross ost wonder creation fill rich orchestra synthes sound ambianc one music major factor yet time uplift vigor favourit track includ scar left time girl stole star anoth world',\n",
       " 'good true probabl greatest soundtrack histori usual better play game first enjoy anyway work hard get soundtrack spend money get realli worth everi penni get ost amaz first track danc around delight especi scar left time buy',\n",
       " 'reason price reason cd expens even version not importsom best music ever could listen everi track everi minut everi day say']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    all_reviews = list()\n",
    "    lines = df[\"review\"].values.astype(str).tolist()\n",
    "    for text in lines:\n",
    "        #1\n",
    "        text = text.lower()\n",
    "        #2\n",
    "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text = pattern.sub('', text)\n",
    "        #3\n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        #4\n",
    "        tokens = word_tokenize(text)\n",
    "        #5\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        #6\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        #7\n",
    "        SB = SnowballStemmer(language='english')\n",
    "        words = [SB.stem(w) for w in words if not w in stop_words]\n",
    "        #8\n",
    "        words = ' '.join(words)\n",
    "        all_reviews.append(words)\n",
    "        \n",
    "    return all_reviews\n",
    "print(stopwords.words(\"english\"))\n",
    "all_reviews = clean_text(dfEnglish)\n",
    "all_reviews[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-drama",
   "metadata": {
    "id": "lesser-drama"
   },
   "source": [
    "# Term frequency and word relevance\n",
    "We cleaned all the reviews from words and things that do not include sentiment, but even then, not all words contribute to a positive/negative meaning therefore we have to give each word a \"value\" for our model to know how important or relevant that word is in contributing to sentiment.\n",
    "\n",
    "\n",
    "We have a method that implement it:\n",
    "1. TFIDFVectorizer : TFIDF is a statistical measurring method. It consists of 2 parts, TF (Term Frequency) multiplied with IDF (Inverse Document Frequency). The main intuition being some words that appear frequently in 1 document and less frequently in other documents could be considered as providing extra insight for that 1 document and could help our model learn from this additional piece of information. In short, common words are penalized. These are relative frequencies identified as floating point numbers.\n",
    "\n",
    "We test both models to see which gives us better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "municipal-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD with TfidfVectorizer results:\n",
      "Training accuracy: 0.9064320579436309\n",
      "Test accuracy: 0.8669500866005353\n",
      "Precision: 0.8611449451887941\n"
     ]
    }
   ],
   "source": [
    "#We define TfidfVectorizer and we give it our reviews to transform and our classes\n",
    "TV = TfidfVectorizer(min_df=3)   \n",
    "X = TV.fit_transform(all_reviews).toarray()\n",
    "y = dfEnglish['score'].to_numpy()\n",
    "\n",
    "#We split the data to train and test by 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "#We define our first model, SGD, we train it and test the results\n",
    "model = SGDClassifier(loss='hinge')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('SGD with TfidfVectorizer results:')\n",
    "\n",
    "print('Training accuracy:', model.score(X_train,y_train))\n",
    "print('Test accuracy:', model.score(X_test,y_test))\n",
    "print('Precision:',precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qualified-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "TFfilename = 'finalized_TFIDF.sav'\n",
    "pickle.dump(TV, open(TFfilename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reported-mongolia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD with TfidfVectorizer results:\n",
      "Training accuracy: 0.9064320579436309\n",
      "Test accuracy: 0.8669500866005353\n",
      "Precision: 0.8611449451887941\n"
     ]
    }
   ],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print('SGD with TfidfVectorizer results:')\n",
    "\n",
    "print('Training accuracy:', loaded_model.score(X_train,y_train))\n",
    "print('Test accuracy:', loaded_model.score(X_test,y_test))\n",
    "print('Precision:',precision_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy_of_AmazonReviewProject.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "fd7a215fbf8ba5128c0fd7e31862e7b6298d02c184c1d2bfc8d09962c7e5f7d9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
